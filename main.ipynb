{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fer\n",
    "#pip install tensorflow\n",
    "#pip install cv2\n",
    "#pip install numpy\n",
    "#pip install pandas\n",
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c55964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "#image capture\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"sam.jpg\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().magic('matplotlib inline')\n",
    "\n",
    "from fer import FER\n",
    "%matplotlib inline\n",
    "\n",
    "test_image_one = plt.imread(\"sam.jpg\")\n",
    "emo_detector = FER(mtcnn=True)\n",
    "# Capture all the emotions on the image\n",
    "captured_emotions = emo_detector.detect_emotions(test_image_one)\n",
    "# Print all captured emotions with the image\n",
    "print(captured_emotions)\n",
    "plt.imshow(test_image_one)\n",
    "\n",
    "#Reading the image with opencv\n",
    "img = cv2.imread(\"sam.jpg\")\n",
    "\n",
    "#declaring global variables (are used later on)\n",
    "clicked = False\n",
    "r = g = b = xpos = ypos = 0\n",
    "\n",
    "#Reading csv file with pandas and giving names to each column\n",
    "index=[\"color\",\"color_name\",\"hex\",\"R\",\"G\",\"B\"]\n",
    "csv = pd.read_csv('colors.csv', names=index, header=None)\n",
    "\n",
    "#function to calculate minimum distance from all colors and get the most matching color\n",
    "def getColorName(R,G,B):\n",
    "    minimum = 10000\n",
    "    for i in range(len(csv)):\n",
    "        d = abs(R- int(csv.loc[i,\"R\"])) + abs(G- int(csv.loc[i,\"G\"]))+ abs(B- int(csv.loc[i,\"B\"]))\n",
    "        if(d<=minimum):\n",
    "            minimum = d\n",
    "            cname = csv.loc[i,\"color_name\"]\n",
    "    return cname\n",
    "\n",
    "#function to get x,y coordinates of mouse double click\n",
    "def draw_function(event, x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        global b,g,r,xpos,ypos, clicked\n",
    "        clicked = True\n",
    "        xpos = x\n",
    "        ypos = y\n",
    "        b,g,r = img[y,x]\n",
    "        b = int(b)\n",
    "        g = int(g)\n",
    "        r = int(r)\n",
    "       \n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_function)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    cv2.imshow(\"image\",img)\n",
    "    if (clicked):\n",
    "   \n",
    "        #cv2.rectangle(image, startpoint, endpoint, color, thickness)-1 fills entire rectangle \n",
    "        cv2.rectangle(img,(20,20), (750,60), (b,g,r), -1)\n",
    "\n",
    "        #Creating text string to display( Color name and RGB values )\n",
    "        text = getColorName(r,g,b) + ' R='+ str(r) +  ' G='+ str(g) +  ' B='+ str(b)\n",
    "        \n",
    "        #cv2.putText(img,text,start,font(0-7),fontScale,color,thickness,lineType )\n",
    "        cv2.putText(img, text,(50,50),2,0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        #For very light colours we will display text in black colour\n",
    "        if(r+g+b>=600):\n",
    "            cv2.putText(img, text,(50,50),2,0.8,(0,0,0),2,cv2.LINE_AA)\n",
    "            \n",
    "        clicked=False\n",
    "\n",
    "    #Break the loop when user hits 'esc' key    \n",
    "    if cv2.waitKey(20) & 0xFF ==27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Loading the image to be tested\n",
    "test_image = cv2.imread('sam.jpg')\n",
    "\n",
    "# Converting to grayscale as opencv expects detector takes in input gray scale images\n",
    "test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Displaying grayscale image\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "\n",
    "# Since we know that OpenCV loads an image in BGR format so we need to convert it into RBG format to be able to display its true colours. Let us write a small function for that.\n",
    "\n",
    "\n",
    "\n",
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# # Haar cascade files\n",
    "\n",
    "# Loading the classifier for frontal face\n",
    "\n",
    "\n",
    "haar_cascade_face = cv2.CascadeClassifier('data/haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "\n",
    "# # Face detection\n",
    "\n",
    "\n",
    "faces_rects = haar_cascade_face.detectMultiScale(test_image_gray, scaleFactor = 1.2, minNeighbors = 5);\n",
    "\n",
    "# Let us print the no. of faces found\n",
    "print('Faces found: ', len(faces_rects))\n",
    "\n",
    "\n",
    "\n",
    "# Our next step is to loop over all the co-ordinates it returned and draw rectangles around them using Open CV.We will be drawing a green rectangle with thicknessof 2\n",
    "\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces_rects:\n",
    "     cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "\n",
    "# Finally, we shall display the original image in coloured to see if the face has been detected correctly or not.\n",
    "\n",
    "\n",
    "#convert image to RGB and show image\n",
    "plt.imshow(convertToRGB(test_image))\n",
    "\n",
    "\n",
    "#  Let us create a generalised function for the entire face detection process.\n",
    "\n",
    "\n",
    "def detect_faces(cascade, test_image, scaleFactor = 1.1):\n",
    "    # create a copy of the image to prevent any changes to the original one.\n",
    "    image_copy = test_image.copy()\n",
    "    \n",
    "    #convert the test image to gray scale as opencv face detector expects gray images\n",
    "    gray_image = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Applying the haar classifier to detect faces\n",
    "    faces_rect = cascade.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors = 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        cv2.rectangle(image_copy, (x, y), (x+w, y+h), (0, 255, 0), 15)\n",
    "        \n",
    "    return image_copy\n",
    "\n",
    "\n",
    "# Testing the function on new image\n",
    "\n",
    "\n",
    "#loading image\n",
    "test_image2 = cv2.imread('sam.jpg')\n",
    "\n",
    "#call the function to detect faces\n",
    "faces = detect_faces(haar_cascade_face, test_image2)\n",
    "\n",
    "#convert to RGB and display image\n",
    "plt.imshow(convertToRGB(faces))\n",
    "\n",
    "# Saving the final image\n",
    "\n",
    "cv2.imwrite('image1.png',faces)\n",
    "\n",
    "#image to color chart\n",
    "image = cv2.imread('sam.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def rgb_to_hex(rgb_color):\n",
    "    hex_color = \"#\"\n",
    "    for i in rgb_color:\n",
    "        i = int(i)\n",
    "        hex_color += (\"{:02x}\".format(i))\n",
    "    return hex_color\n",
    "\n",
    "def prep_image(raw_img):\n",
    "    modified_img = cv2.resize(raw_img, (900, 600), interpolation = cv2.INTER_AREA)\n",
    "    modified_img = modified_img.reshape(modified_img.shape[0]*modified_img.shape[1], 3)\n",
    "    return modified_img\n",
    "\n",
    "def color_analysis(img):\n",
    "    clf = KMeans(n_clusters = 5)\n",
    "    color_labels = clf.fit_predict(img)\n",
    "    center_colors = clf.cluster_centers_\n",
    "    counts = Counter(color_labels)\n",
    "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
    "    hex_colors = [rgb_to_hex(ordered_colors[i]) for i in counts.keys()]\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.pie(counts.values(), labels = hex_colors, colors = hex_colors,autopct='%0.2f%%')\n",
    "    plt.savefig(\"color_analysis_report.png\")\n",
    "    print(hex_colors)\n",
    "    \n",
    "modified_image = prep_image(image)\n",
    "color_analysis(modified_image)\n",
    "\n",
    "\n",
    "#Gender and age Detection\n",
    "\n",
    "FACE_PROTO = \"deploy.prototxt.txt\"\n",
    "FACE_MODEL = \"res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "GENDER_MODEL = 'deploy_gender.prototxt'\n",
    "GENDER_PROTO = 'gender_net.caffemodel'\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_MODEL = 'deploy_age.prototxt'\n",
    "AGE_PROTO = 'age_net.caffemodel'\n",
    "AGE_INTERVALS = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)',\n",
    "                 '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "\n",
    "# Initialize frame size\n",
    "frame_width = 1280\n",
    "frame_height = 720\n",
    "# load face Caffe model\n",
    "face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n",
    "# Load age prediction model\n",
    "age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)\n",
    "# Load gender prediction model\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_MODEL, GENDER_PROTO)\n",
    "\n",
    "def get_faces(frame, confidence_threshold=0.5):\n",
    "    # convert the frame into a blob to be ready for NN input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
    "    # set the image as input to the NN\n",
    "    face_net.setInput(blob)\n",
    "    # perform inference and get predictions\n",
    "    output = np.squeeze(face_net.forward())\n",
    "    # initialize the result list\n",
    "    faces = []\n",
    "    # Loop over the faces detected\n",
    "    for i in range(output.shape[0]):\n",
    "        confidence = output[i, 2]\n",
    "        if confidence > confidence_threshold:\n",
    "            box = output[i, 3:7] * \\\n",
    "                np.array([frame.shape[1], frame.shape[0],\n",
    "                         frame.shape[1], frame.shape[0]])\n",
    "            # convert to integers\n",
    "            start_x, start_y, end_x, end_y = box.astype(np.int)\n",
    "            # widen the box a little\n",
    "            start_x, start_y, end_x, end_y = start_x - \\\n",
    "                10, start_y - 10, end_x + 10, end_y + 10\n",
    "            start_x = 0 if start_x < 0 else start_x\n",
    "            start_y = 0 if start_y < 0 else start_y\n",
    "            end_x = 0 if end_x < 0 else end_x\n",
    "            end_y = 0 if end_y < 0 else end_y\n",
    "            # append to our list\n",
    "            faces.append((start_x, start_y, end_x, end_y))\n",
    "    return faces\n",
    "\n",
    "def display_img(title, img):\n",
    "    \"\"\"Displays an image on screen and maintains the output until the user presses a key\"\"\"\n",
    "    # Display Image on screen\n",
    "    cv2.imshow(title, img)\n",
    "    # Mantain output until user presses a key\n",
    "    cv2.waitKey(0)\n",
    "    # Destroy windows when user presses a key\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# from: https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    # resize the image\n",
    "    return cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "def get_gender_predictions(face_img):\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image=face_img, scalefactor=1.0, size=(227, 227),\n",
    "        mean=MODEL_MEAN_VALUES, swapRB=False, crop=False\n",
    "    )\n",
    "    gender_net.setInput(blob)\n",
    "    return gender_net.forward()\n",
    "\n",
    "\n",
    "def get_age_predictions(face_img):\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image=face_img, scalefactor=1.0, size=(227, 227),\n",
    "        mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "    )\n",
    "    age_net.setInput(blob)\n",
    "    return age_net.forward()\n",
    "\n",
    "def predict_age_and_gender(input_path: str):\n",
    "    \"\"\"Predict the gender of the faces showing in the image\"\"\"\n",
    "    # Initialize frame size\n",
    "    # frame_width = 1280\n",
    "    # frame_height = 720\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # resize the image, uncomment if you want to resize the image\n",
    "    # img = cv2.resize(img, (frame_width, frame_height))\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    # predict the faces\n",
    "    faces = get_faces(frame)\n",
    "    # Loop over the faces detected\n",
    "    # for idx, face in enumerate(faces):\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        age_preds = get_age_predictions(face_img)\n",
    "        gender_preds = get_gender_predictions(face_img)\n",
    "        i = gender_preds[0].argmax()\n",
    "        gender = GENDER_LIST[i]\n",
    "        gender_confidence_score = gender_preds[0][i]\n",
    "        i = age_preds[0].argmax()\n",
    "        age = AGE_INTERVALS[i]\n",
    "        age_confidence_score = age_preds[0][i]\n",
    "        # Draw the box\n",
    "        label = f\"{gender}-{gender_confidence_score*100:.1f}%, {age}-{age_confidence_score*100:.1f}%\"\n",
    "        # label = \"{}-{:.2f}%\".format(gender, gender_confidence_score*100)\n",
    "        print(label)\n",
    "        yPos = start_y - 15\n",
    "        while yPos < 15:\n",
    "            yPos += 15\n",
    "        box_color = (255, 0, 0) if gender == \"Male\" else (147, 20, 255)\n",
    "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), box_color, 2)\n",
    "        # Label processed image\n",
    "        font_scale = 0.54\n",
    "        cv2.putText(frame, label, (start_x, yPos),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, box_color, 2)\n",
    "\n",
    "        # Display processed image\n",
    "    display_img(\"Gender Estimator\", frame)\n",
    "    # uncomment if you want to save the image\n",
    "    cv2.imwrite(\"output.jpg\", frame)\n",
    "    # Cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    input_path = sys.argv[1]\n",
    "    predict_age_and_gender('sam.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
